{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "# from src.algorithm import improve_system\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At this point, we've run some examples through our LLM graph. If not, refer to this [post](https://langchain-ai.github.io/langgraph/tutorials/introduction/) to get started.\n",
    "\n",
    "#### We have a graph, let's save it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example-data/graph-healthcare.json\", \"r\") as json_file:\n",
    "    graph_json = json.load(json_file)\n",
    "\n",
    "edges = graph_json[\"edges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.middleware import convert_edges_to_dag\n",
    "\n",
    "dag = convert_edges_to_dag(edges=edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in dataset with your prompts and LLM responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_responses = pd.read_excel(\"example-data/healthcare-responses.xlsx\")\n",
    "llm_responses = llm_responses.tail(10)\n",
    "llm_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use LLM-as-a-Judge to run the responses for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm_as_judge import run_validation_using_LLM\n",
    "\n",
    "# node_input_output_mappings = {\n",
    "#     \"extract_keywords_from_title\": (\"prompt-1\", \"output-keywords\"),\n",
    "#     \"tool_search\": (\"prompt-2\", \"output-article_search\"),\n",
    "#     \"summarize_tone_sentiment_of_replies\": (\"prompt-3\", \"output-replies\"),\n",
    "#     \"generate_reply\": ( \"prompt-4\", \"output-reply\")\n",
    "# }\n",
    "\n",
    "node_input_output_mappings = {\n",
    "    \"pii_name_number_email\": (\"prompt-1\", \"response-1\"),\n",
    "    \"pii_id\": (\"prompt-1\", \"response-2\"),\n",
    "    \"pii_birthdate\": (\"prompt-1\", \"response-3\"),\n",
    "    \"pii_medications\": (\"prompt-1\", \"response-4\"),\n",
    "    \"pii_insurance\": (\"prompt-1\", \"response-5\"),\n",
    "    \"extractor\": (\"prompt-1\", \"response-6\"),\n",
    "    \"summarizer\": (\"prompt-1\", \"response-7\"),\n",
    "}\n",
    "\n",
    "llm_response_df = run_validation_using_LLM(\n",
    "    dataframe=llm_responses, node_input_output_mappings=node_input_output_mappings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipe import convert_to_dag, run_validation_using_llm, find_problematic_node\n",
    "# # \"Systematic Chain Improvement and Problem Evaluation\"\n",
    "\n",
    "# # We have the graph from langgraph\n",
    "# graph = Langgraph()\n",
    "# # Middleware to convert it to a format that we need\n",
    "# # People can write this however\n",
    "# dag = convert_to_dag(graph) # We'll need this later\n",
    "\n",
    "# data_of_inputs_outputs = pd.DataFrame()\n",
    "\n",
    "# llm_responses_df = run_validation_using_llm(data_of_inputs_outputs)\n",
    "\n",
    "# node = find_problematic_node(llm_responses_df)\n",
    "\n",
    "# print(node)\n",
    "\n",
    "# \"Node: 1 is problematic\"\n",
    "# \"It has 33% chance of failing on it's own, compared to 9% chance of failing\"\n",
    "# \"because of node(n-1). Please focus on fixing Node 1.\"\n",
    "\n",
    "# ## What are some ways node 1 can be fixed.\n",
    "# ## Could we analyze it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improve_system(data=llm_response_df, dag=dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing node: summarizer\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(summarizer fails | extractor fails): 0.0000\n",
      "\n",
      "Analyzing node: extractor\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(extractor fails | pii_insurance fails): 0.0000\n",
      "\n",
      "Analyzing node: pii_insurance\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(pii_insurance fails | pii_medications fails): 0.0000\n",
      "\n",
      "Analyzing node: pii_medications\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(pii_medications fails | pii_birthdate fails): 0.0000\n",
      "\n",
      "Analyzing node: pii_birthdate\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(pii_birthdate fails | pii_id fails): 0.0000\n",
      "\n",
      "Analyzing node: pii_id\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(pii_id fails | pii_name_number_email fails): 0.0000\n",
      "\n",
      "Analyzing node: pii_name_number_email\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "\n",
      "upstream_final_probs {}\n",
      "upstream_final_probs {}\n",
      "upstream_final_probs {}\n",
      "upstream_final_probs {}\n",
      "upstream_final_probs {}\n",
      "upstream_final_probs {}\n",
      "\n",
      "Root cause analysis complete.\n",
      "Debug path (from downstream to upstream): summarizer -> extractor -> pii_insurance -> pii_medications -> pii_birthdate -> pii_id -> pii_name_number_email\n",
      "Most likely root cause (most upstream issue): pii_name_number_email\n",
      "Independent failure probability of root cause: 0.0000\n",
      "Conditional failure probabilities given root cause's dependency failures:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  result = (node_fails & dep_fails).sum() / dep_fails.sum()\n",
      "/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  result = (node_fails & dep_fails).sum() / dep_fails.sum()\n",
      "/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  result = (node_fails & dep_fails).sum() / dep_fails.sum()\n",
      "/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  result = (node_fails & dep_fails).sum() / dep_fails.sum()\n",
      "/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  result = (node_fails & dep_fails).sum() / dep_fails.sum()\n",
      "/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  result = (node_fails & dep_fails).sum() / dep_fails.sum()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m improver\u001b[38;5;241m.\u001b[39mload_application_graph()\n\u001b[1;32m      7\u001b[0m improver\u001b[38;5;241m.\u001b[39mllm_validations \u001b[38;5;241m=\u001b[39m df\n\u001b[0;32m----> 8\u001b[0m \u001b[43mimprover\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimprove_system\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MIDS/epic-data-lab/scipe/app.py:82\u001b[0m, in \u001b[0;36mLanggraphImprover.improve_system\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_validations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapplication_dag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidations and application graph must be loaded before finding the problematic node.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_problematic_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_validations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplication_dag\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:94\u001b[0m, in \u001b[0;36mfind_problematic_node\u001b[0;34m(data, dag, verbose)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe most likely cause is an independent failure in node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m         most_likely_dep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_probs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe most likely cause is a failure in dependency: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmost_likely_dep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path, independent_prob, final_probs\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from app import LanggraphImprover\n",
    "df = pd.read_excel(\"/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/example-data/llm-evals-healthcare.xlsx\")\n",
    "df = df.iloc[1:10]\n",
    "improver = LanggraphImprover(\"/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/config.yml\")\n",
    "\n",
    "\n",
    "improver.llm_validations = df\n",
    "improver.improve_system()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
