{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root directory to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from app import LanggraphImprover\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At this point, we've run some examples through our LLM graph. If not, refer to this [post](https://langchain-ai.github.io/langgraph/tutorials/introduction/) to get started.\n",
    "\n",
    "#### We have a graph, let's save it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(f\"{project_root}/example_data/healthcare-responses-small.xlsx\")\n",
    "data = data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-59f3d38a-baee-43f2-b72d-8b856ccaaa10', choices=[Choices(finish_reason='stop', index=0, message=Message(content='{\\n  \"reason\": \"The output correctly redacted the patient\\'s name, phone number, and email from the input as per the instructions. The output follows the provided directions.\",\\n  \"validation\": 1\\n}', role='assistant', tool_calls=None, function_call=None))], created=1726700651, model='claude-3-haiku-20240307', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=49, prompt_tokens=2049, total_tokens=2098, completion_tokens_details=None))\n",
      "ModelResponse(id='chatcmpl-44437201-56ea-4f05-9cf1-581276aa39de', choices=[Choices(finish_reason='stop', index=0, message=Message(content='{\\n    \"reason\": \"The output accurately redacted the patient\\'s name, phone number, and email from the given input, as per the instructions.\",\\n    \"validation\": 1\\n}', role='assistant', tool_calls=None, function_call=None))], created=1726700651, model='claude-3-haiku-20240307', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=44, prompt_tokens=2043, total_tokens=2087, completion_tokens_details=None))\n",
      "ModelResponse(id='chatcmpl-4530a865-5ec1-4443-9b97-518a09629968', choices=[Choices(finish_reason='stop', index=0, message=Message(content='{\\n    \"reason\": \"The output follows the instructions in the input correctly. All the patient\\'s name, phone number, and email have been redacted as requested.\",\\n    \"validation\": 1\\n}', role='assistant', tool_calls=None, function_call=None))], created=1726700652, model='claude-3-haiku-20240307', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=47, prompt_tokens=2044, total_tokens=2091, completion_tokens_details=None))\n",
      "ModelResponse(id='chatcmpl-3794c95f-0a22-4721-9703-43a42113c42a', choices=[Choices(finish_reason='stop', index=0, message=Message(content='{\\n    \"reason\": \"The output follows the instructions in the input to redact the patient\\'s name, phone number, and email from the given input text.\",\\n    \"validation\": 1\\n}', role='assistant', tool_calls=None, function_call=None))], created=1726700653, model='claude-3-haiku-20240307', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=46, prompt_tokens=2043, total_tokens=2089, completion_tokens_details=None))\n",
      "ModelResponse(id='chatcmpl-a35d2060-9313-4d31-979a-b3c385a36958', choices=[Choices(finish_reason='stop', index=0, message=Message(content='{\\n    \"reason\": \"The output follows the instructions in the input by redacting the patient\\'s name, phone number, and email from the call transcript.\",\\n    \"validation\": 1\\n}', role='assistant', tool_calls=None, function_call=None))], created=1726700654, model='claude-3-haiku-20240307', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=45, prompt_tokens=2044, total_tokens=2089, completion_tokens_details=None))\n",
      "ModelResponse(id='chatcmpl-42e61701-4a0d-4198-b8b6-7b05ffc4015a', choices=[Choices(finish_reason='stop', index=0, message=Message(content='{\\n    \"reason\": \"The output follows the input instructions by redacting the patient\\'s name, phone number, and email address, and summarizing the key details of the interaction, including the main reason for the call, the symptoms described by the customer, and the recommendations provided by the agent.\",\\n    \"validation\": 1\\n}', role='assistant', tool_calls=None, function_call=None))], created=1726700655, model='claude-3-haiku-20240307', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=73, prompt_tokens=1258, total_tokens=1331, completion_tokens_details=None))\n",
      "ModelResponse(id='chatcmpl-b6c761b0-f1ef-4fb1-8cb1-35b5c8e834ae', choices=[Choices(finish_reason='stop', index=0, message=Message(content='{\\n    \"reason\": \"The output accurately summarizes the key details from the input, including the patient\\'s concerns about their insurance coverage and billing, the agent\\'s plan to investigate the issue further with the billing department and insurance provider, and the agent\\'s recommendation for the patient to hold off on making any payments until the issue is resolved. The output covers the relevant information from the input without exceeding any word limits or including unnecessary details.\",\\n    \"validation\": 1\\n}', role='assistant', tool_calls=None, function_call=None))], created=1726700656, model='claude-3-haiku-20240307', object='chat.completion', system_fingerprint=None, usage=Usage(completion_tokens=101, prompt_tokens=1248, total_tokens=1349, completion_tokens_details=None))\n",
      "Analyzing node: summarizer\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(summarizer fails | extractor fails): 0.0000\n",
      "\n",
      "Analyzing node: extractor\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(extractor fails | pii_insurance fails): 0.0000\n",
      "\n",
      "Analyzing node: pii_insurance\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(pii_insurance fails | pii_medications fails): 0.0000\n",
      "\n",
      "Analyzing node: pii_medications\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(pii_medications fails | pii_birthdate fails): 0.0000\n",
      "\n",
      "Analyzing node: pii_birthdate\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(pii_birthdate fails | pii_id fails): 0.0000\n",
      "\n",
      "Analyzing node: pii_id\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "  P(pii_id fails | pii_name_number_email fails): 0.0000\n",
      "\n",
      "Analyzing node: pii_name_number_email\n",
      "Overall failure probability for this node: 0.0000\n",
      "Independent failure probability: 0.0000\n",
      "Node failure because dep fails: 0\n",
      "Conditional failure probabilities given upstream dependency failures:\n",
      "\n",
      "\n",
      "Root cause analysis complete.\n",
      "Debug path (from downstream to upstream): summarizer -> extractor -> pii_insurance -> pii_medications -> pii_birthdate -> pii_id -> pii_name_number_email\n",
      "Most likely root cause (most upstream issue): pii_name_number_email\n",
      "Independent failure probability of root cause: 0.0000\n",
      "Conditional failure probabilities given root cause's dependency failures:\n",
      "The most likely cause is a failure in dependency: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  result = (node_fails & dep_fails).sum() / dep_fails.sum()\n",
      "/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  result = (node_fails & dep_fails).sum() / dep_fails.sum()\n",
      "/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  result = (node_fails & dep_fails).sum() / dep_fails.sum()\n",
      "/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  result = (node_fails & dep_fails).sum() / dep_fails.sum()\n",
      "/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  result = (node_fails & dep_fails).sum() / dep_fails.sum()\n",
      "/Users/ankushgarg/Desktop/MIDS/epic-data-lab/scipe/src/algorithm.py:25: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  result = (node_fails & dep_fails).sum() / dep_fails.sum()\n"
     ]
    }
   ],
   "source": [
    "improver = LanggraphImprover(f\"{project_root}/config.yml\")\n",
    "await improver.improve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".scipe_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
